{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 5:Detect Hands.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaTWIwzsjnwm"
      },
      "source": [
        "Import necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXOkuxFh2ovI"
      },
      "source": [
        "#Use Javascript code to call your local webcam\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "#Convert the image type that captured by webcam\n",
        "from base64 import b64decode, b64encode\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import io\n",
        "# OpenCV library \n",
        "import cv2 \n",
        "# plot the img\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNqMk1bMecSC"
      },
      "source": [
        "### Mount your google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeH3mumsENhD",
        "outputId": "4e96b797-e5cf-4e2e-e8b6-82293c0f010b"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1wvPHprENAf"
      },
      "source": [
        "# Load cascades using v2.CascadeClassifier\n",
        "faces_cascades = cv2.CascadeClassifier(\"/content/drive/MyDrive/Computer_Vision/haarcascade_frontalface_default.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhXHldfLeI-C"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "### The following code takes care of using your webcame, take a capture and send it to collab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzUa1IW8xjSq"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "\n",
        "def VideoCapture():\n",
        "  js = Javascript('''\n",
        "    async function create(){\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.setAttribute('playsinline', '');\n",
        "\n",
        "      div.appendChild(video);\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      await video.play();\n",
        "\n",
        "      canvas =  document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      div_out = document.createElement('div');\n",
        "      document.body.appendChild(div_out);\n",
        "      img = document.createElement('img');\n",
        "      div_out.appendChild(img);\n",
        "    }\n",
        "\n",
        "    async function capture(){\n",
        "        return await new Promise(function(resolve, reject){\n",
        "            pendingResolve = resolve;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            result = canvas.toDataURL('image/jpeg', 0.20);\n",
        "\n",
        "            pendingResolve(result);\n",
        "        })\n",
        "    }\n",
        "\n",
        "    function showimg(imgb64){\n",
        "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "  display(js)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEZcOgx5jzoT"
      },
      "source": [
        "### Define the Image Conversion function\n",
        "\n",
        "For VideoCapture functions return images with base64 type\n",
        "\n",
        "For cv2 need images with bytes type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vVQFfsTMlsq"
      },
      "source": [
        "def b64_to_bytes(byte):\n",
        "  jpeg = b64decode(byte.split(',')[1])\n",
        "  im = Image.open(io.BytesIO(jpeg))\n",
        "  return np.array(im)\n",
        "\n",
        "def bytes_to_b64(image):\n",
        "  image = Image.fromarray(image)\n",
        "  buffer = io.BytesIO()\n",
        "  image.save(buffer, 'jpeg')\n",
        "  buffer.seek(0)\n",
        "  x = b64encode(buffer.read()).decode('utf-8')\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIT9TIIl9DHO"
      },
      "source": [
        "# This function scales a rotated rectangle by a factor of scale_x (width) and scale_y (height)\n",
        "def scale_contour(pts, scale_x, scale_y):\n",
        "    M = cv2.moments(pts)\n",
        "\n",
        "    if M['m00'] == 0:\n",
        "      return pts\n",
        "\n",
        "    cx = int(M['m10']/M['m00'])\n",
        "    cy = int(M['m01']/M['m00'])\n",
        "\n",
        "    cnt_norm = pts - [cx, cy]\n",
        "    cnt_scaled = cnt_norm * np.array([scale_x, scale_y])\n",
        "    cnt_scaled = cnt_scaled + [cx, cy]\n",
        "    cnt_scaled = cnt_scaled.astype(np.int32)\n",
        "\n",
        "    return cnt_scaled\n",
        "\n",
        "# Will be needed in task 6 maybe\n",
        "def crop_hand(im, pts):\n",
        "    rect = cv2.minAreaRect(pts)\n",
        "\n",
        "    # get the parameter of the small rectangle\n",
        "    center, size, angle = rect[0], rect[1], rect[2]\n",
        "    center, size = tuple(map(int, center)), tuple(map(int, size))\n",
        "\n",
        "    # get row and col num in img\n",
        "    height, width = im.shape[0], im.shape[1]\n",
        "\n",
        "    # calculate the rotation matrix\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1)\n",
        "    # rotate the original image\n",
        "    img_rot = cv2.warpAffine(im, M, (width, height))\n",
        "\n",
        "    # now rotated rectangle becomes vertical, and we crop it\n",
        "    img_crop = cv2.getRectSubPix(img_rot, size, center)\n",
        "\n",
        "    return img_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y6uOPbYEYAV"
      },
      "source": [
        "# Detect faces using cascades\n",
        "def detect_faces(img, cascades):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  faces = cascades.detectMultiScale(gray, 1.3, 4)\n",
        "  return faces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71q1AaEwEFDU"
      },
      "source": [
        "# Capture a frame used for histogramm backprojection\n",
        "VideoCapture()\n",
        "eval_js('create()')\n",
        "\n",
        "while True:\n",
        "  response = input(\"Type anything when ready!:\")\n",
        "  byte = eval_js('capture()')\n",
        "  im = b64_to_bytes(byte)\n",
        "  im_copy = im.copy()\n",
        "  faces = detect_faces(im, faces_cascades)\n",
        "\n",
        "  if len(faces) == 1:\n",
        "    face = faces[0]\n",
        "    cv2.rectangle(im_copy,(face[0],face[1]),(face[0] + face[2], face[1] + face[3]),(0,255,0),2)\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "  eval_js('showimg(\"{}\")'.format(bytes_to_b64(im_copy)))\n",
        "  response = input(\"Use this bounding box? [y or n]:\")\n",
        "  if response == 'y':\n",
        "    frame = im[face[1]:face[1]+face[3], face[0]:face[0]+face[2]]\n",
        "    eval_js('showimg(\"{}\")'.format(bytes_to_b64(frame)))\n",
        "    tracking_window_face = face # Initial tracking window for the face\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEotoQkMMVIR"
      },
      "source": [
        "Compute the face histogram and prob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPgFckJ0rwXt"
      },
      "source": [
        "def show_hist(hist):\n",
        "  bin_count = hist.shape[0]\n",
        "  bin_w = 24\n",
        "  img = np.zeros((256, bin_count*bin_w, 3), np.uint8)\n",
        "  for i in range(bin_count):\n",
        "      h = int(hist[i])\n",
        "      cv2.rectangle(img, (i*bin_w+2, 255), ((i+1)*bin_w-2, 255-h), (int(180.0*i/bin_count), 255, 255), -1)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
        "  cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "CEOgsy8IhEZh",
        "outputId": "eb01f056-7155-46f5-f21e-9c86247e7b1e"
      },
      "source": [
        "# Compute the the histogram\n",
        "# Transform the frame into HSV\n",
        "frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "# Create an inRange mask for pixels. Limit the saturation in [64., 255.] and brightness in [32., 200.]\n",
        "# only contains white and black color\n",
        "mask = cv2.inRange(frame_hsv, np.array((0., 64., 32.)), np.array((180., 255., 200.)))\n",
        "# Compute the histogram of the frame (use only the HUE channel). See `https://bit.ly/3pdVUEd`\n",
        "# Take into account only pixels which are not too bright and not too dark (use the previous mask)\n",
        "# Use 16 bins and speicfy the range of the hue ([0, 180])\n",
        "frame_hist = cv2.calcHist([frame_hsv], [0], mask, [16], [0,180])\n",
        "# Normalize the histogram between 0 (lowest intensity) and 255 (highest intensity) (use MinMax normalization `cv.NORM_MINMAX`) using the method `https://bit.ly/3jMGhCj`\n",
        "frame_hist = cv2.normalize(frame_hist, frame_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "# Reashape the histogram into a 1-D array (use `.reshape(-1)`)\n",
        "frame_hist = frame_hist.reshape(-1)\n",
        "# Show the histogram\n",
        "show_hist(frame_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAIAAAA1FTYwAAAD20lEQVR4nO3dMUrEQBiA0US8hFiJxxAr8RhiJR5DPIZYiccQK/EYYiXewrXZsDZiMYsf6HtVmvxMFvKRZmbnCf6ek9XQ7Y/zltbBD3bqBQD/lwABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyAgQkBEgICNAQEaAgIwAARkBAjK79QLgi7vV0O3n85bWwS/xBQRkBAjICBCQESAgI0BARoCAjAABGQECMgIEZAQIyNiKAd/am4a2hrxPtob8wBcQkBEgICNAQEaAgIwAARkBAjICBGQECMgIEJARICAjQEBGgICMAAEZAQIyAgRk1ucBjf0h7ubUk9XZ2Jz7Zc7D2JzT9cXb2IPtLw92NTbneplzMDbndfNDHw0Nmp+XOTdjcy7XFx9jD7bzx8/NuRp7w66XN+xlbM7hMmc1PY3MmafjZc7F2JzbT7/DIQZrol8dAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=384x256 at 0x7FC1F0DB5B10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBZOoYJnoEto"
      },
      "source": [
        "VideoCapture()\n",
        "eval_js('create()')\n",
        "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "byte = eval_js('capture()')\n",
        "im = b64_to_bytes(byte)\n",
        "im_width, im_height = im.shape[1],im.shape[0]\n",
        "\n",
        "\n",
        "# Because we dont know where our hands are, we search it in entire image\n",
        "tracking_window_hand = (0,0,im_width,im_height) # Define the initial tracking window for the hand. It spans the entire caption\n",
        "\n",
        "\n",
        "while True:\n",
        "  byte = eval_js('capture()')\n",
        "  im = b64_to_bytes(byte)\n",
        "  # Transform the image into HSV\n",
        "  hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)  \n",
        "  # Compute the standard not too bright not too dark mask\n",
        "  mask = cv2.inRange(hsv, np.array((0., 64., 32.)), np.array((180., 200., 200.)))\n",
        "  # Back project the histogramm on the hsv img\n",
        "  prob = cv2.calcBackProject([hsv], [0], frame_hist, [0,180], scale=1) \n",
        "  # Apply the mask\n",
        "  prob = prob & mask\n",
        "   \n",
        "  # First look up for the face using cam shift starting from `tracking_window_face`\n",
        "  (x,y,w,h) = tracking_window_face\n",
        "  bbox, tracking_window_face = cv2.CamShift(prob, tracking_window_face, term_crit)\n",
        "\n",
        "\n",
        "  # Retrieve the rotated bounding rectangle\n",
        "  pts = cv2.boxPoints(bbox).astype(np.int)\n",
        "  # Scale the rotated bounding box 1.5x times  \n",
        "  scaled_pts = scale_contour(pts, 1.5, 1.5)# Use `scale_contour`\n",
        "\n",
        "  # Fill the rotated face bounding box with 0 in the prob map\n",
        "  # Use `cv2.fillPoly`\n",
        "  cv2.fillPoly(prob, [scaled_pts], 0)\n",
        "\n",
        "  # Draw the boundix box around the face\n",
        "  cv2.polylines(im, [pts], True, (255, 0, 0), 2)\n",
        "  # Draw the scaled boundix box around the face\n",
        "  cv2.polylines(im, [scaled_pts], True, (0, 255 , 0), 2)\n",
        "\n",
        "  # Now look up for the hand using cam shift starting from `tracking_window_hand`\n",
        "  bbox, tracking_window_hand = cv2.CamShift(prob, tracking_window_hand, term_crit)\n",
        "  pts = cv2.boxPoints(bbox).astype(np.int)\n",
        "\n",
        "  # Scale the contour around the hand\n",
        "  pts = scale_contour(pts, 1.8, 1.5)\n",
        "  cv2.polylines(im, [pts], True, (0, 0, 255), 2)\n",
        "\n",
        "  ## Draw the boundix box around the hand\n",
        "  #eval_js('showimg(\"{}\")'.format(bytes_to_b64(prob)))\n",
        "  eval_js('showimg(\"{}\")'.format(bytes_to_b64(im)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ymqvD1xjM-RY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vX-cqq378S66"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dRsWHew0QQDE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}